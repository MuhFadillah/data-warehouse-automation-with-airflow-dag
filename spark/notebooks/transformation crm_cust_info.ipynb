{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6296658-43d6-4552-89e7-70d817d1802a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/23 13:05:55 WARN Utils: Your hostname, lenovo-PC resolves to a loopback address: 127.0.1.1; using 172.31.112.46 instead (on interface eth0)\n",
      "25/05/23 13:05:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ubuntucoy/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntucoy/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntucoy/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "com.amazonaws#aws-java-sdk-bundle added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-6bfc46d6-909f-4cb8-a1cb-41d66dec870e;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.1026 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 4204ms :: artifacts dl 59ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.1026 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.2 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 by [com.amazonaws#aws-java-sdk-bundle;1.11.1026] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   4   |   0   |   0   |   1   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-6bfc46d6-909f-4cb8-a1cb-41d66dec870e\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/245ms)\n",
      "25/05/23 13:06:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/23 13:06:22 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/05/23 13:07:02 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "25/05/23 13:07:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ELT_PySpark\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.2,com.amazonaws:aws-java-sdk-bundle:1.11.901\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://localhost:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de227aa-8f2f-4145-9dc8-da57d25a0605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/23 13:07:29 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------+------------+------------------+--------+---------------+\n",
      "|cst_id|   cst_key|cst_firstname|cst_lastname|cst_marital_status|cst_gndr|cst_create_date|\n",
      "+------+----------+-------------+------------+------------------+--------+---------------+\n",
      "| 11000|AW00011000|          Jon|       Yang |                 M|       M|     2025-10-06|\n",
      "| 11001|AW00011001|       Eugene|     Huang  |                 S|       M|     2025-10-06|\n",
      "| 11002|AW00011002|        Ruben|      Torres|                 M|       M|     2025-10-06|\n",
      "| 11003|AW00011003|      Christy|         Zhu|                 S|       F|     2025-10-06|\n",
      "| 11004|AW00011004|    Elizabeth|     Johnson|                 S|       F|     2025-10-06|\n",
      "| 11005|AW00011005|        Julio|        Ruiz|                 S|       M|     2025-10-06|\n",
      "| 11006|AW00011006|        Janet|     Alvarez|                 S|       F|     2025-10-06|\n",
      "| 11007|AW00011007|        Marco|       Mehta|                 M|       M|     2025-10-06|\n",
      "| 11008|AW00011008|          Rob|     Verhoff|                 S|       F|     2025-10-06|\n",
      "| 11009|AW00011009|      Shannon|     Carlson|                 S|       M|     2025-10-06|\n",
      "| 11010|AW00011010|    Jacquelyn|      Suarez|                 S|       F|     2025-10-06|\n",
      "| 11011|AW00011011|       Curtis|          Lu|                 M|       M|     2025-10-06|\n",
      "| 11012|AW00011012|       Lauren|      Walker|                 M|       F|     2025-10-06|\n",
      "| 11013|AW00011013|         Ian |    Jenkins |                 M|       M|     2025-10-06|\n",
      "| 11014|AW00011014|       Sydney|     Bennett|                 S|       F|     2025-10-06|\n",
      "| 11015|AW00011015|        Chloe|       Young|                 S|       F|     2025-10-06|\n",
      "| 11016|AW00011016|        Wyatt|        Hill|                 M|       M|     2025-10-07|\n",
      "| 11017|AW00011017|      Shannon|        Wang|                 S|       F|     2025-10-07|\n",
      "| 11018|AW00011018|     Clarence|         Rai|                 S|       M|     2025-10-07|\n",
      "| 11019|AW00011019|         Luke|         Lal|                 S|       M|     2025-10-07|\n",
      "+------+----------+-------------+------------+------------------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"s3a://raw/crm/cust_info.csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4d4bf20-4751-4cc0-b1f8-0005dd51f54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------+------------+------------------+--------+---------------+\n",
      "|cst_id|   cst_key|cst_firstname|cst_lastname|cst_marital_status|cst_gndr|cst_create_date|\n",
      "+------+----------+-------------+------------+------------------+--------+---------------+\n",
      "| 11000|AW00011000|          Jon|        Yang|           Married|    Male|     2025-10-06|\n",
      "| 11001|AW00011001|       Eugene|       Huang|            Single|    Male|     2025-10-06|\n",
      "| 11002|AW00011002|        Ruben|      Torres|           Married|    Male|     2025-10-06|\n",
      "| 11003|AW00011003|      Christy|         Zhu|            Single|  Female|     2025-10-06|\n",
      "| 11004|AW00011004|    Elizabeth|     Johnson|            Single|  Female|     2025-10-06|\n",
      "| 11005|AW00011005|        Julio|        Ruiz|            Single|    Male|     2025-10-06|\n",
      "| 11006|AW00011006|        Janet|     Alvarez|            Single|  Female|     2025-10-06|\n",
      "| 11007|AW00011007|        Marco|       Mehta|           Married|    Male|     2025-10-06|\n",
      "| 11008|AW00011008|          Rob|     Verhoff|            Single|  Female|     2025-10-06|\n",
      "| 11009|AW00011009|      Shannon|     Carlson|            Single|    Male|     2025-10-06|\n",
      "| 11010|AW00011010|    Jacquelyn|      Suarez|            Single|  Female|     2025-10-06|\n",
      "| 11011|AW00011011|       Curtis|          Lu|           Married|    Male|     2025-10-06|\n",
      "| 11012|AW00011012|       Lauren|      Walker|           Married|  Female|     2025-10-06|\n",
      "| 11013|AW00011013|          Ian|     Jenkins|           Married|    Male|     2025-10-06|\n",
      "| 11014|AW00011014|       Sydney|     Bennett|            Single|  Female|     2025-10-06|\n",
      "| 11015|AW00011015|        Chloe|       Young|            Single|  Female|     2025-10-06|\n",
      "| 11016|AW00011016|        Wyatt|        Hill|           Married|    Male|     2025-10-07|\n",
      "| 11017|AW00011017|      Shannon|        Wang|            Single|  Female|     2025-10-07|\n",
      "| 11018|AW00011018|     Clarence|         Rai|            Single|    Male|     2025-10-07|\n",
      "| 11019|AW00011019|         Luke|         Lal|            Single|    Male|     2025-10-07|\n",
      "+------+----------+-------------+------------+------------------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, trim, upper, when, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Step 1: Window specification\n",
    "window_spec = Window.partitionBy(\"cst_id\").orderBy(col(\"cst_create_date\").desc())\n",
    "\n",
    "# Step 2: Filtering null dulu + apply transformasi\n",
    "df_transformed = (\n",
    "    df.filter(col(\"cst_id\").isNotNull())\n",
    "      .select(\n",
    "        \"cst_id\",\n",
    "        \"cst_key\",\n",
    "        trim(col(\"cst_firstname\")).alias(\"cst_firstname\"),\n",
    "        trim(col(\"cst_lastname\")).alias(\"cst_lastname\"),\n",
    "        when(upper(trim(col(\"cst_marital_status\"))) == \"S\", \"Single\")\n",
    "            .when(upper(trim(col(\"cst_marital_status\"))) == \"M\", \"Married\")\n",
    "            .otherwise(\"n/a\")\n",
    "            .alias(\"cst_marital_status\"),\n",
    "        when(upper(trim(col(\"cst_gndr\"))) == \"F\", \"Female\")\n",
    "            .when(upper(trim(col(\"cst_gndr\"))) == \"M\", \"Male\")\n",
    "            .otherwise(\"n/a\")\n",
    "            .alias(\"cst_gndr\"),\n",
    "        \"cst_create_date\"\n",
    "      )\n",
    "      .withColumn(\"flag_last\", row_number().over(window_spec))  # buat kolom untuk filter\n",
    "      .filter(col(\"flag_last\") == 1)  # filter\n",
    "      .drop(\"flag_last\")  # drop kolomnya supaya gak muncul di output\n",
    ")\n",
    "\n",
    "df_transformed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f6f719-5e0e-415c-b3a5-463da0a6e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/23 13:08:21 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "25/05/23 13:08:24 WARN AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_transformed.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(\"s3a://clean/crm/cust_info_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5efffb17-6bc1-4bd6-8d32-60f000e31a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------+------------+------------------+--------+---------------+\n",
      "|cst_id|   cst_key|cst_firstname|cst_lastname|cst_marital_status|cst_gndr|cst_create_date|\n",
      "+------+----------+-------------+------------+------------------+--------+---------------+\n",
      "| 11000|AW00011000|          Jon|        Yang|           Married|    Male|     2025-10-06|\n",
      "| 11001|AW00011001|       Eugene|       Huang|            Single|    Male|     2025-10-06|\n",
      "| 11002|AW00011002|        Ruben|      Torres|           Married|    Male|     2025-10-06|\n",
      "| 11003|AW00011003|      Christy|         Zhu|            Single|  Female|     2025-10-06|\n",
      "| 11004|AW00011004|    Elizabeth|     Johnson|            Single|  Female|     2025-10-06|\n",
      "| 11005|AW00011005|        Julio|        Ruiz|            Single|    Male|     2025-10-06|\n",
      "| 11006|AW00011006|        Janet|     Alvarez|            Single|  Female|     2025-10-06|\n",
      "| 11007|AW00011007|        Marco|       Mehta|           Married|    Male|     2025-10-06|\n",
      "| 11008|AW00011008|          Rob|     Verhoff|            Single|  Female|     2025-10-06|\n",
      "| 11009|AW00011009|      Shannon|     Carlson|            Single|    Male|     2025-10-06|\n",
      "| 11010|AW00011010|    Jacquelyn|      Suarez|            Single|  Female|     2025-10-06|\n",
      "| 11011|AW00011011|       Curtis|          Lu|           Married|    Male|     2025-10-06|\n",
      "| 11012|AW00011012|       Lauren|      Walker|           Married|  Female|     2025-10-06|\n",
      "| 11013|AW00011013|          Ian|     Jenkins|           Married|    Male|     2025-10-06|\n",
      "| 11014|AW00011014|       Sydney|     Bennett|            Single|  Female|     2025-10-06|\n",
      "| 11015|AW00011015|        Chloe|       Young|            Single|  Female|     2025-10-06|\n",
      "| 11016|AW00011016|        Wyatt|        Hill|           Married|    Male|     2025-10-07|\n",
      "| 11017|AW00011017|      Shannon|        Wang|            Single|  Female|     2025-10-07|\n",
      "| 11018|AW00011018|     Clarence|         Rai|            Single|    Male|     2025-10-07|\n",
      "| 11019|AW00011019|         Luke|         Lal|            Single|    Male|     2025-10-07|\n",
      "+------+----------+-------------+------------+------------------+--------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = spark.read.option(\"header\", True).csv(\"s3a://clean/crm/cust_info_clean.csv\")\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3946800c-7ce1-4629-ba08-a085ba4debeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<duckdb.duckdb.DuckDBPyConnection at 0x7fe847607e70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "\n",
    "# Convert dari Spark ke Pandas\n",
    "df_cleaned_cust_info = df_cleaned.toPandas()\n",
    "\n",
    "# Connect ke DuckDB\n",
    "con = duckdb.connect(\"/mnt/d/data_engineering/duckdb/db/dev.duckdb\")\n",
    "\n",
    "# Simpan sebagai tabel DuckDB (view)\n",
    "con.register(\"crm_cust_info_clean_view\", df_cleaned_cust_info)\n",
    "\n",
    "# Simpan sebagai tabel DuckDB (bukan view)\n",
    "con.execute(\"CREATE OR REPLACE TABLE crm_cust_info_clean AS SELECT * FROM crm_cust_info_clean_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2f3086d-052b-4b61-9749-e2e53d1df51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_34785\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_34785_level0_col0\" class=\"col_heading level0 col0\" >cst_id</th>\n",
       "      <th id=\"T_34785_level0_col1\" class=\"col_heading level0 col1\" >cst_key</th>\n",
       "      <th id=\"T_34785_level0_col2\" class=\"col_heading level0 col2\" >cst_firstname</th>\n",
       "      <th id=\"T_34785_level0_col3\" class=\"col_heading level0 col3\" >cst_lastname</th>\n",
       "      <th id=\"T_34785_level0_col4\" class=\"col_heading level0 col4\" >cst_marital_status</th>\n",
       "      <th id=\"T_34785_level0_col5\" class=\"col_heading level0 col5\" >cst_gndr</th>\n",
       "      <th id=\"T_34785_level0_col6\" class=\"col_heading level0 col6\" >cst_create_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_34785_row0_col0\" class=\"data row0 col0\" >11000</td>\n",
       "      <td id=\"T_34785_row0_col1\" class=\"data row0 col1\" >AW00011000</td>\n",
       "      <td id=\"T_34785_row0_col2\" class=\"data row0 col2\" >Jon</td>\n",
       "      <td id=\"T_34785_row0_col3\" class=\"data row0 col3\" >Yang</td>\n",
       "      <td id=\"T_34785_row0_col4\" class=\"data row0 col4\" >Married</td>\n",
       "      <td id=\"T_34785_row0_col5\" class=\"data row0 col5\" >Male</td>\n",
       "      <td id=\"T_34785_row0_col6\" class=\"data row0 col6\" >2025-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_34785_row1_col0\" class=\"data row1 col0\" >11001</td>\n",
       "      <td id=\"T_34785_row1_col1\" class=\"data row1 col1\" >AW00011001</td>\n",
       "      <td id=\"T_34785_row1_col2\" class=\"data row1 col2\" >Eugene</td>\n",
       "      <td id=\"T_34785_row1_col3\" class=\"data row1 col3\" >Huang</td>\n",
       "      <td id=\"T_34785_row1_col4\" class=\"data row1 col4\" >Single</td>\n",
       "      <td id=\"T_34785_row1_col5\" class=\"data row1 col5\" >Male</td>\n",
       "      <td id=\"T_34785_row1_col6\" class=\"data row1 col6\" >2025-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_34785_row2_col0\" class=\"data row2 col0\" >11002</td>\n",
       "      <td id=\"T_34785_row2_col1\" class=\"data row2 col1\" >AW00011002</td>\n",
       "      <td id=\"T_34785_row2_col2\" class=\"data row2 col2\" >Ruben</td>\n",
       "      <td id=\"T_34785_row2_col3\" class=\"data row2 col3\" >Torres</td>\n",
       "      <td id=\"T_34785_row2_col4\" class=\"data row2 col4\" >Married</td>\n",
       "      <td id=\"T_34785_row2_col5\" class=\"data row2 col5\" >Male</td>\n",
       "      <td id=\"T_34785_row2_col6\" class=\"data row2 col6\" >2025-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_34785_row3_col0\" class=\"data row3 col0\" >11003</td>\n",
       "      <td id=\"T_34785_row3_col1\" class=\"data row3 col1\" >AW00011003</td>\n",
       "      <td id=\"T_34785_row3_col2\" class=\"data row3 col2\" >Christy</td>\n",
       "      <td id=\"T_34785_row3_col3\" class=\"data row3 col3\" >Zhu</td>\n",
       "      <td id=\"T_34785_row3_col4\" class=\"data row3 col4\" >Single</td>\n",
       "      <td id=\"T_34785_row3_col5\" class=\"data row3 col5\" >Female</td>\n",
       "      <td id=\"T_34785_row3_col6\" class=\"data row3 col6\" >2025-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_34785_row4_col0\" class=\"data row4 col0\" >11004</td>\n",
       "      <td id=\"T_34785_row4_col1\" class=\"data row4 col1\" >AW00011004</td>\n",
       "      <td id=\"T_34785_row4_col2\" class=\"data row4 col2\" >Elizabeth</td>\n",
       "      <td id=\"T_34785_row4_col3\" class=\"data row4 col3\" >Johnson</td>\n",
       "      <td id=\"T_34785_row4_col4\" class=\"data row4 col4\" >Single</td>\n",
       "      <td id=\"T_34785_row4_col5\" class=\"data row4 col5\" >Female</td>\n",
       "      <td id=\"T_34785_row4_col6\" class=\"data row4 col6\" >2025-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_34785_row5_col0\" class=\"data row5 col0\" >11005</td>\n",
       "      <td id=\"T_34785_row5_col1\" class=\"data row5 col1\" >AW00011005</td>\n",
       "      <td id=\"T_34785_row5_col2\" class=\"data row5 col2\" >Julio</td>\n",
       "      <td id=\"T_34785_row5_col3\" class=\"data row5 col3\" >Ruiz</td>\n",
       "      <td id=\"T_34785_row5_col4\" class=\"data row5 col4\" >Single</td>\n",
       "      <td id=\"T_34785_row5_col5\" class=\"data row5 col5\" >Male</td>\n",
       "      <td id=\"T_34785_row5_col6\" class=\"data row5 col6\" >2025-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_34785_row6_col0\" class=\"data row6 col0\" >11006</td>\n",
       "      <td id=\"T_34785_row6_col1\" class=\"data row6 col1\" >AW00011006</td>\n",
       "      <td id=\"T_34785_row6_col2\" class=\"data row6 col2\" >Janet</td>\n",
       "      <td id=\"T_34785_row6_col3\" class=\"data row6 col3\" >Alvarez</td>\n",
       "      <td id=\"T_34785_row6_col4\" class=\"data row6 col4\" >Single</td>\n",
       "      <td id=\"T_34785_row6_col5\" class=\"data row6 col5\" >Female</td>\n",
       "      <td id=\"T_34785_row6_col6\" class=\"data row6 col6\" >2025-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_34785_row7_col0\" class=\"data row7 col0\" >11007</td>\n",
       "      <td id=\"T_34785_row7_col1\" class=\"data row7 col1\" >AW00011007</td>\n",
       "      <td id=\"T_34785_row7_col2\" class=\"data row7 col2\" >Marco</td>\n",
       "      <td id=\"T_34785_row7_col3\" class=\"data row7 col3\" >Mehta</td>\n",
       "      <td id=\"T_34785_row7_col4\" class=\"data row7 col4\" >Married</td>\n",
       "      <td id=\"T_34785_row7_col5\" class=\"data row7 col5\" >Male</td>\n",
       "      <td id=\"T_34785_row7_col6\" class=\"data row7 col6\" >2025-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_34785_row8_col0\" class=\"data row8 col0\" >11008</td>\n",
       "      <td id=\"T_34785_row8_col1\" class=\"data row8 col1\" >AW00011008</td>\n",
       "      <td id=\"T_34785_row8_col2\" class=\"data row8 col2\" >Rob</td>\n",
       "      <td id=\"T_34785_row8_col3\" class=\"data row8 col3\" >Verhoff</td>\n",
       "      <td id=\"T_34785_row8_col4\" class=\"data row8 col4\" >Single</td>\n",
       "      <td id=\"T_34785_row8_col5\" class=\"data row8 col5\" >Female</td>\n",
       "      <td id=\"T_34785_row8_col6\" class=\"data row8 col6\" >2025-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_34785_row9_col0\" class=\"data row9 col0\" >11009</td>\n",
       "      <td id=\"T_34785_row9_col1\" class=\"data row9 col1\" >AW00011009</td>\n",
       "      <td id=\"T_34785_row9_col2\" class=\"data row9 col2\" >Shannon</td>\n",
       "      <td id=\"T_34785_row9_col3\" class=\"data row9 col3\" >Carlson</td>\n",
       "      <td id=\"T_34785_row9_col4\" class=\"data row9 col4\" >Single</td>\n",
       "      <td id=\"T_34785_row9_col5\" class=\"data row9 col5\" >Male</td>\n",
       "      <td id=\"T_34785_row9_col6\" class=\"data row9 col6\" >2025-10-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fe88821fa90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.execute(\"SELECT * FROM crm_cust_info_clean LIMIT 10\").df().style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15dec00e-adc2-4468-bbc3-ab850aab2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab4f765-5f4e-4709-94d7-b3180d4aadbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (spark_venv)",
   "language": "python",
   "name": "spark_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
